{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD3pnzIyszNrjVoLIldQSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvsmihir1/ML-Lab/blob/main/ML7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SXRyYNSMvVa",
        "outputId": "4a931b03-8b60-4f88-e8ab-776caa0258e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting VitalDB\n",
            "  Downloading vitaldb-1.4.9-py3-none-any.whl.metadata (520 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from VitalDB) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from VitalDB) (2.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from VitalDB) (2.32.3)\n",
            "Collecting wfdb (from VitalDB)\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->VitalDB) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->VitalDB) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->VitalDB) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->VitalDB) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->VitalDB) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->VitalDB) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->VitalDB) (2024.8.30)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->VitalDB) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb->VitalDB) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->VitalDB) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->VitalDB) (3.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->VitalDB) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->VitalDB) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->VitalDB) (2.22)\n",
            "Downloading vitaldb-1.4.9-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wfdb, VitalDB\n",
            "Successfully installed VitalDB-1.4.9 wfdb-4.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install VitalDB\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "pjUzv5G8AXqi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcases = pd.read_csv(\"https://api.vitaldb.net/cases\")"
      ],
      "metadata": {
        "id": "Z5EH78fMM7eO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Initialize the sizes of input, hidden, and output layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights with random values for the connections between layers\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "\n",
        "        # Initialize biases for hidden and output layers to zero\n",
        "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.bias_output = np.zeros((1, self.output_size))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # Sigmoid activation function to introduce non-linearity\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        # Derivative of the sigmoid function for backpropagation\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        # Compute the activation of the hidden layer\n",
        "        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_activation)\n",
        "\n",
        "        # Compute the activation of the output layer\n",
        "        self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.predicted_output = self.sigmoid(self.output_activation)\n",
        "\n",
        "        # Return the predicted output from the network\n",
        "        return self.predicted_output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Compute the error at the output layer\n",
        "        output_error = y.reshape(-1, 1) - self.predicted_output  # Ensure y matches the output dimensions\n",
        "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output)\n",
        "\n",
        "        # Compute the error at the hidden layer\n",
        "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases for the hidden to output layer connections\n",
        "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "        # Update weights and biases for the input to hidden layer connections\n",
        "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate, conv=0.2):\n",
        "        # Train the neural network over a specified number of epochs\n",
        "        for epoch in range(epochs):\n",
        "            # Perform a feedforward pass to get predictions\n",
        "            output = self.feedforward(X)\n",
        "            # Perform a backward pass to update weights and biases\n",
        "            self.backward(X, y, learning_rate)\n",
        "            # Calculate loss as mean squared error between actual and predicted outputs\n",
        "            loss = np.mean(np.square(y - output))\n",
        "            # Check for convergence; stop training if loss falls below threshold\n",
        "            if conv > loss:\n",
        "                break  # Exit training loop if convergence is achieved\n"
      ],
      "metadata": {
        "id": "iHxvB2cQKJQD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract height, weight, and bmi values from the DataFrame\n",
        "height = dfcases[\"height\"].values  # Get height values as a NumPy array\n",
        "weight = dfcases[\"weight\"].values  # Get weight values as a NumPy array\n",
        "bmi = dfcases[\"bmi\"].values        # Get BMI values as a NumPy array\n",
        "\n",
        "# Create feature matrix X by combining height and weight into pairs\n",
        "X = np.array([[y, x] for x, y in zip(height, weight)])  # Each row contains [height, weight]\n",
        "\n",
        "# Create target vector y containing BMI values\n",
        "y = np.array([i for i in bmi])  # Convert BMI values into a NumPy array\n",
        "\n",
        "# Initialize the neural network with specified input size, hidden size, and output size\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)\n",
        "\n",
        "# Train the neural network using the feature matrix X and target vector y\n",
        "nn.train(X, y, epochs=1000, learning_rate=0.1, conv=0.002)\n",
        "\n",
        "# Perform a feedforward pass to get predictions on the training data\n",
        "output = nn.feedforward(X)\n",
        "\n",
        "# Print the predicted output (BMI) from the neural network\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gVVj2fEQ7HV",
        "outputId": "75355fd3-7b22-4dda-9546-87f590d4e852"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary of hyperparameter distributions for tuning the MLPClassifier\n",
        "param_distributions_mlp = {\n",
        "    'hidden_layer_sizes': [(50,)],  # Tuple specifying the number of neurons in hidden layers\n",
        "    'activation': ['relu', 'tanh', 'logistic'],  # Activation functions to choose from\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],  # Optimization algorithms for weight updates\n",
        "    'alpha': [0.002, 0.001, 0.01],  # Regularization parameter to prevent overfitting\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],  # Learning rate strategies\n",
        "    'max_iter': [100, 500, 1000],  # Maximum number of iterations for training\n",
        "    'tol': [1e-3, 1e-4, 1e-5]  # Tolerance for stopping criteria; training stops if loss improvement is below this threshold\n",
        "}\n",
        "\n",
        "# Initialize the MLPClassifier with specified parameters\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(6,),  # Set a hidden layer with 6 neurons\n",
        "    activation='logistic',     # Use logistic activation function for neurons\n",
        "    solver='lbfgs',           # Use the LBFGS optimization algorithm\n",
        "    max_iter=1000             # Set maximum iterations for training to 1000\n",
        ")"
      ],
      "metadata": {
        "id": "GAfkXQHlJ99v"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up RandomizedSearchCV for hyperparameter tuning of the MLPClassifier\n",
        "random_search_mlp = RandomizedSearchCV(\n",
        "    estimator=mlp,                        # The MLPClassifier instance to be tuned\n",
        "    param_distributions=param_distributions_mlp,  # The hyperparameter space to explore\n",
        "    n_iter=10,                            # Number of different combinations to try\n",
        "    cv=5,                                 # Number of cross-validation folds\n",
        "    scoring='accuracy',                   # Metric to evaluate the performance of each combination\n",
        "    verbose=2,                            # Level of verbosity; higher values show more details during the search\n",
        "    random_state=0                        # Seed for reproducibility of results\n",
        ")"
      ],
      "metadata": {
        "id": "waRgQsEWMaOr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and labels\n",
        "height = dfcases[\"height\"].values\n",
        "weight = dfcases[\"weight\"].values\n",
        "bmi = dfcases[\"bmi\"].values\n"
      ],
      "metadata": {
        "id": "rGfbh7ENNu3Y"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature matrix X by combining height and weight into pairs\n",
        "X = np.array([[h, w] for h, w in zip(height, weight)])  # Each row contains [height, weight]\n",
        "\n",
        "# Convert BMI to categorical labels using digitization\n",
        "# The bins define the thresholds for categorizing BMI:\n",
        "# - 0 for underweight (BMI < 18.5)\n",
        "# - 1 for normal weight (18.5 <= BMI < 24.9)\n",
        "# - 2 for overweight (BMI >= 24.9)\n",
        "y = np.digitize(bmi, bins=[18.5, 24.9])  # Assigns categories based on defined bins\n",
        "\n",
        "# Fit the MLP model using RandomizedSearchCV\n",
        "random_search_mlp.fit(X, y)  # Train the MLP model with the feature matrix X and labels y\n",
        "\n",
        "# Initialize Perceptron model\n",
        "perceptron = Perceptron()  # Create an instance of the Perceptron classifier\n",
        "\n",
        "# Define parameter distributions for Perceptron hyperparameter tuning\n",
        "param_distributions_perceptron = {\n",
        "    'penalty': ['l2', 'l1', 'elasticnet', None],  # Regularization penalties to apply\n",
        "    'alpha': [0.0001, 0.001, 0.01],               # Learning rate parameter\n",
        "    'max_iter': [1000, 2000, 3000],               # Maximum number of iterations for training\n",
        "    'tol': [1e-3, 1e-4, 1e-5]                     # Tolerance for stopping criteria; training stops if improvement is below this threshold\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAgdVHOdN3OK",
        "outputId": "9c5b01ec-036a-4793-b943-1d61b776fa2f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   5.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   4.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   5.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   0.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   4.7s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   4.4s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   3.8s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   1.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   6.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   7.1s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   5.7s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   9.0s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   1.4s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   7.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.8s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   0.4s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.8s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.6s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.4s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize RandomizedSearchCV for Perceptron to tune hyperparameters\n",
        "random_search_perceptron = RandomizedSearchCV(\n",
        "    estimator=perceptron,                        # The Perceptron instance to be tuned\n",
        "    param_distributions=param_distributions_perceptron,  # The hyperparameter space to explore\n",
        "    n_iter=10,                                   # Number of different combinations to try\n",
        "    cv=5,                                        # Number of cross-validation folds to use\n",
        "    scoring='accuracy',                          # Metric to evaluate the performance of each combination\n",
        "    verbose=2,                                   # Level of verbosity; higher values show more details during the search\n",
        "    random_state=0                               # Seed for reproducibility of results\n",
        ")\n",
        "\n",
        "# Fit the Perceptron model using RandomizedSearchCV\n",
        "random_search_perceptron.fit(X, y)             # Train the Perceptron model with the feature matrix X and labels y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_0iCh9BTN61s",
        "outputId": "be023a20-d511-40d4-9092-8889caa6f638"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=None, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=None, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=None, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=None, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=None, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l1, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l1, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l1, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l1, tol=0.001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l1, tol=0.001; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=3000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=3000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=3000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=3000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END .alpha=0.0001, max_iter=3000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ..alpha=0.01, max_iter=3000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END ..alpha=0.01, max_iter=3000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END ..alpha=0.01, max_iter=3000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END ..alpha=0.01, max_iter=3000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END ..alpha=0.01, max_iter=3000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END .alpha=0.01, max_iter=3000, penalty=None, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.01, max_iter=3000, penalty=None, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.01, max_iter=3000, penalty=None, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.01, max_iter=3000, penalty=None, tol=1e-05; total time=   0.0s\n",
            "[CV] END .alpha=0.01, max_iter=3000, penalty=None, tol=1e-05; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=2000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=2000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=2000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=2000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.0001, max_iter=2000, penalty=l1, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=2000, penalty=l2, tol=1e-05; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=Perceptron(),\n",
              "                   param_distributions={'alpha': [0.0001, 0.001, 0.01],\n",
              "                                        'max_iter': [1000, 2000, 3000],\n",
              "                                        'penalty': ['l2', 'l1', 'elasticnet',\n",
              "                                                    None],\n",
              "                                        'tol': [0.001, 0.0001, 1e-05]},\n",
              "                   random_state=0, scoring='accuracy', verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=Perceptron(),\n",
              "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01],\n",
              "                                        &#x27;max_iter&#x27;: [1000, 2000, 3000],\n",
              "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                    None],\n",
              "                                        &#x27;tol&#x27;: [0.001, 0.0001, 1e-05]},\n",
              "                   random_state=0, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=Perceptron(),\n",
              "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01],\n",
              "                                        &#x27;max_iter&#x27;: [1000, 2000, 3000],\n",
              "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                    None],\n",
              "                                        &#x27;tol&#x27;: [0.001, 0.0001, 1e-05]},\n",
              "                   random_state=0, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Perceptron</label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron(max_iter=2000, penalty=&#x27;l1&#x27;, tol=0.0001)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Perceptron<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron(max_iter=2000, penalty=&#x27;l1&#x27;, tol=0.0001)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Perceptron Hyperparameters:\", random_search_perceptron.best_params_)\n",
        "print(\"Best Perceptron Accuracy:\", random_search_perceptron.best_score_)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Print best hyperparameters and scores for MLP\n",
        "print(\"Best MLP Hyperparameters:\", random_search_mlp.best_params_)\n",
        "print(\"Best MLP Accuracy:\", random_search_mlp.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W_lDKzNPj-0",
        "outputId": "e607207b-6792-4acd-c1e3-7eb057a6728d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Perceptron Hyperparameters: {'tol': 0.0001, 'penalty': 'l1', 'max_iter': 2000, 'alpha': 0.0001}\n",
            "Best Perceptron Accuracy: 0.8141740900462378\n",
            "\n",
            "\n",
            "Best MLP Hyperparameters: {'tol': 0.001, 'solver': 'lbfgs', 'max_iter': 500, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (50,), 'alpha': 0.002, 'activation': 'logistic'}\n",
            "Best MLP Accuracy: 0.9466085296255038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract height, weight, and BMI values from the DataFrame\n",
        "height = dfcases[\"height\"].values  # Get height values as a NumPy array\n",
        "weight = dfcases[\"weight\"].values  # Get weight values as a NumPy array\n",
        "bmi = dfcases[\"bmi\"].values        # Get BMI values as a NumPy array\n",
        "\n",
        "# Create feature matrix X by combining height and weight into pairs\n",
        "X = np.array([[y, x] for x, y in zip(height, weight)])  # Each row contains [height, weight]\n",
        "\n",
        "# Create target vector y containing BMI values\n",
        "y = np.array([i for i in bmi])  # Convert BMI values into a NumPy array\n",
        "\n",
        "# Initialize the MLPClassifier with specified parameters\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='lbfgs', max_iter=10000000000000000)\n",
        "\n",
        "# Convert target vector y to integers (if necessary)\n",
        "y = y.astype('int')  # Ensure that y is of integer type for classification\n",
        "\n",
        "# Fit the MLP model using the feature matrix X and target vector y\n",
        "mlp.fit(X, y)  # Train the MLP model on the data\n",
        "\n",
        "# Make predictions and print results for the first few samples (up to 100)\n",
        "for i in range(len(X)//100):  # Loop through every 100th sample\n",
        "    prediction = mlp.predict([X[i]])[0]  # Predict the output for the current input sample\n",
        "    print(f\"Input: {X[i]}, Target: {y[i]}, Prediction: {prediction}\")  # Print input, target, and predicted output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGOC1PBRPlfN",
        "outputId": "bc395913-1b37-41ac-99ef-c3bb62d10331"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [ 67.5 160.2], Target: 26, Prediction: 23\n",
            "Input: [ 54.8 167.3], Target: 19, Prediction: 23\n",
            "Input: [ 69.7 169.1], Target: 24, Prediction: 23\n",
            "Input: [ 53.  160.6], Target: 20, Prediction: 23\n",
            "Input: [ 59.7 171. ], Target: 20, Prediction: 23\n",
            "Input: [ 54.6 150. ], Target: 24, Prediction: 23\n",
            "Input: [ 62.3 167.7], Target: 22, Prediction: 23\n",
            "Input: [ 67.25 156.7 ], Target: 27, Prediction: 23\n",
            "Input: [ 50.9 157.9], Target: 20, Prediction: 23\n",
            "Input: [ 62.75 162.5 ], Target: 23, Prediction: 23\n",
            "Input: [ 81.45 175.4 ], Target: 26, Prediction: 23\n",
            "Input: [ 81.4 169.2], Target: 28, Prediction: 23\n",
            "Input: [ 64.9 153. ], Target: 27, Prediction: 23\n",
            "Input: [ 80.  177.9], Target: 25, Prediction: 23\n",
            "Input: [ 48.3 158. ], Target: 19, Prediction: 23\n",
            "Input: [ 68.9 162.3], Target: 26, Prediction: 23\n",
            "Input: [ 53.  164.2], Target: 19, Prediction: 23\n",
            "Input: [ 56.9 155. ], Target: 23, Prediction: 23\n",
            "Input: [ 66.2 171.3], Target: 22, Prediction: 23\n",
            "Input: [ 61.3 173.6], Target: 20, Prediction: 23\n",
            "Input: [ 61.6 155.1], Target: 25, Prediction: 23\n",
            "Input: [ 54.6 162. ], Target: 20, Prediction: 23\n",
            "Input: [ 47.8 139.4], Target: 24, Prediction: 23\n",
            "Input: [ 65.  161.8], Target: 24, Prediction: 23\n",
            "Input: [ 80.2 169.7], Target: 27, Prediction: 23\n",
            "Input: [ 62.6 169.7], Target: 21, Prediction: 23\n",
            "Input: [ 43.35 143.2 ], Target: 21, Prediction: 23\n",
            "Input: [ 49.9 148.9], Target: 22, Prediction: 23\n",
            "Input: [ 57.4 156.1], Target: 23, Prediction: 23\n",
            "Input: [ 57.6 166.4], Target: 20, Prediction: 23\n",
            "Input: [ 53.8 162.8], Target: 20, Prediction: 23\n",
            "Input: [ 71.9 169.4], Target: 25, Prediction: 23\n",
            "Input: [ 88.  171.8], Target: 29, Prediction: 23\n",
            "Input: [ 66.6 150.5], Target: 29, Prediction: 23\n",
            "Input: [ 50.4 155.2], Target: 20, Prediction: 23\n",
            "Input: [ 50.2 155.6], Target: 20, Prediction: 23\n",
            "Input: [ 82.75 180.5 ], Target: 25, Prediction: 23\n",
            "Input: [ 72.3 170.1], Target: 25, Prediction: 23\n",
            "Input: [ 64.7 162.5], Target: 24, Prediction: 23\n",
            "Input: [ 83.2 160.1], Target: 32, Prediction: 23\n",
            "Input: [ 78.7 175. ], Target: 25, Prediction: 23\n",
            "Input: [ 72.5 166.7], Target: 26, Prediction: 23\n",
            "Input: [ 52.9 172.4], Target: 17, Prediction: 23\n",
            "Input: [ 59.9 175.8], Target: 19, Prediction: 23\n",
            "Input: [ 50.  147.9], Target: 22, Prediction: 23\n",
            "Input: [ 53.75 150.7 ], Target: 23, Prediction: 23\n",
            "Input: [ 48.7 167.1], Target: 17, Prediction: 23\n",
            "Input: [ 56.2 160.3], Target: 21, Prediction: 23\n",
            "Input: [ 67.5 165.8], Target: 24, Prediction: 23\n",
            "Input: [ 51.6 158.1], Target: 20, Prediction: 23\n",
            "Input: [ 55.3 165.5], Target: 20, Prediction: 23\n",
            "Input: [ 67.3 173.5], Target: 22, Prediction: 23\n",
            "Input: [ 66.1 167.7], Target: 23, Prediction: 23\n",
            "Input: [ 71.9 165. ], Target: 26, Prediction: 23\n",
            "Input: [ 59.2 175.1], Target: 19, Prediction: 23\n",
            "Input: [ 50.3 157.9], Target: 20, Prediction: 23\n",
            "Input: [ 69.7 169.4], Target: 24, Prediction: 23\n",
            "Input: [ 57.8 169.7], Target: 20, Prediction: 23\n",
            "Input: [ 79.4 166. ], Target: 28, Prediction: 23\n",
            "Input: [ 46.8 157. ], Target: 19, Prediction: 23\n",
            "Input: [ 57.3 165.7], Target: 20, Prediction: 23\n",
            "Input: [ 62.4 161.5], Target: 23, Prediction: 23\n",
            "Input: [ 62.7 165.8], Target: 22, Prediction: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_tuning():\n",
        "    # Define parameter distributions for tuning the Perceptron model\n",
        "    param_distributions_perceptron = {\n",
        "        'penalty': ['l2'],  # Perceptron only supports 'l2' regularization\n",
        "        'alpha': [0.001, 0.01, 0.1],  # Learning rate values to test\n",
        "        'max_iter': [100, 500, 1000],  # Maximum iterations for training\n",
        "        'tol': [1e-3, 1e-4, 1e-5]  # Tolerance for stopping criteria\n",
        "    }\n",
        "\n",
        "    # Initialize the Perceptron model with a random state for reproducibility\n",
        "    perceptron = Perceptron(random_state=0)\n",
        "\n",
        "    # Set up RandomizedSearchCV for hyperparameter tuning of the Perceptron model\n",
        "    random_search_perceptron = RandomizedSearchCV(\n",
        "        estimator=perceptron,  # The Perceptron instance to be tuned\n",
        "        param_distributions=param_distributions_perceptron,  # Hyperparameter space to explore\n",
        "        n_iter=10,  # Number of different combinations to sample\n",
        "        cv=5,  # Number of cross-validation folds to use\n",
        "        scoring='accuracy',  # Metric to evaluate the performance of each combination\n",
        "        verbose=2,  # Level of verbosity; higher values show more details during the search\n",
        "        random_state=0  # Seed for reproducibility of results\n",
        "    )\n",
        "\n",
        "    # Prepare your data - Ensure y is classification-friendly (binary/multi-class labels)\n",
        "    height = dfcases[\"height\"].values  # Get height values as a NumPy array\n",
        "    weight = dfcases[\"weight\"].values  # Get weight values as a NumPy array\n",
        "    bmi = dfcases[\"bmi\"].values        # Get BMI values as a NumPy array\n",
        "\n",
        "    # Create feature matrix X by combining height and weight into pairs\n",
        "    X = np.array([[y, x] for x, y in zip(height, weight)])  # Each row contains [height, weight]\n",
        "\n",
        "    # Convert BMI to categorical labels using digitization\n",
        "    y = np.digitize(bmi, bins=[18.5, 24.9])  # Assign categories based on defined bins\n",
        "\n",
        "    # Fit the models using RandomizedSearchCV\n",
        "    random_search_perceptron.fit(X, y)  # Train the Perceptron model with the feature matrix X and labels y\n",
        "\n",
        "    # Return best parameters and best score from the search\n",
        "    return random_search_perceptron.best_params_, random_search_perceptron.best_score_"
      ],
      "metadata": {
        "id": "BmcAkS_7Pp8G"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_tuning():\n",
        "    # Define parameter distributions for tuning the MLPClassifier\n",
        "    param_distributions_for_mlp = {\n",
        "        'hidden_layer_sizes': [(50,)],  # Tuple specifying the number of neurons in hidden layers\n",
        "        'activation': ['relu', 'tanh', 'logistic'],  # Activation functions to choose from\n",
        "        'solver': ['lbfgs', 'sgd', 'adam'],  # Optimization algorithms for weight updates\n",
        "        'alpha': [0.002, 0.001, 0.01],  # Regularization parameter to prevent overfitting\n",
        "        'learning_rate': ['constant', 'invscaling', 'adaptive'],  # Learning rate strategies\n",
        "        'max_iter': [100, 500, 1000],  # Maximum number of iterations for training\n",
        "        'tol': [1e-3, 1e-4, 1e-5]  # Tolerance for stopping criteria; training stops if loss improvement is below this threshold\n",
        "    }\n",
        "\n",
        "    # Initialize the MLPClassifier with default parameters (to be tuned)\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(6,), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "\n",
        "    # Set up RandomizedSearchCV for hyperparameter tuning of the MLP model\n",
        "    random_search_mlp = RandomizedSearchCV(\n",
        "        estimator=mlp,  # The MLPClassifier instance to be tuned\n",
        "        param_distributions=param_distributions_for_mlp,  # Hyperparameter space to explore\n",
        "        n_iter=10,  # Number of different combinations to sample\n",
        "        cv=5,  # Number of cross-validation folds to use\n",
        "        scoring='accuracy',  # Metric to evaluate the performance of each combination\n",
        "        verbose=2,  # Level of verbosity; higher values show more details during the search\n",
        "        random_state=0  # Seed for reproducibility of results\n",
        "    )\n",
        "\n",
        "    # Prepare your data - Ensure y is classification-friendly (binary/multi-class labels)\n",
        "    height = dfcases[\"height\"].values  # Get height values as a NumPy array\n",
        "    weight = dfcases[\"weight\"].values  # Get weight values as a NumPy array\n",
        "    bmi = dfcases[\"bmi\"].values        # Get BMI values as a NumPy array\n",
        "\n",
        "    # Create feature matrix X by combining height and weight into pairs\n",
        "    X = np.array([[y, x] for x, y in zip(height, weight)])  # Each row contains [height, weight]\n",
        "\n",
        "    # Convert BMI to categorical labels using digitization\n",
        "    y = np.digitize(bmi, bins=[18.5, 24.9])  # Assign categories based on defined bins\n",
        "\n",
        "    # Fit the models using RandomizedSearchCV\n",
        "    random_search_mlp.fit(X, y)  # Train the MLP model with the feature matrix X and labels y\n",
        "\n",
        "    # Return best parameters and best score from the search\n",
        "    return random_search_mlp.best_params_, random_search_mlp.best_score_"
      ],
      "metadata": {
        "id": "uHC_mw1XP4ai"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def A3():\n",
        "    # Extract height, weight, and BMI values from the DataFrame\n",
        "    height = dfcases[\"height\"].values  # Get height values as a NumPy array\n",
        "    weight = dfcases[\"weight\"].values  # Get weight values as a NumPy array\n",
        "    bmi = dfcases[\"bmi\"].values        # Get BMI values as a NumPy array\n",
        "\n",
        "    # Create feature matrix X by combining height and weight into pairs\n",
        "    X = np.array([[y, x] for x, y in zip(height, weight)])  # Each row contains [height, weight]\n",
        "\n",
        "    # Convert BMI to categorical labels using digitization\n",
        "    y = np.digitize(bmi, bins=[18.5, 24.9])  # Assign categories based on defined bins\n",
        "\n",
        "    # Split data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Set up classifiers with their respective best parameters from previous tuning\n",
        "    model_collection = {\n",
        "        'Perceptron': Perceptron(**random_search_perceptron.best_params_, random_state=42),\n",
        "        'MLP': MLPClassifier(**random_search_mlp.best_params_, random_state=42),\n",
        "        'SVM': SVC(random_state=42),\n",
        "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(random_state=42),\n",
        "        'CatBoost': CatBoostClassifier(random_state=42, verbose=False),\n",
        "        'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "        'XGBoost': XGBClassifier(random_state=42, objective='multi:softprob'),\n",
        "        'Naive Bayes': GaussianNB()\n",
        "    }\n",
        "\n",
        "    # Define evaluation metrics to be calculated for each model\n",
        "    eval_metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "\n",
        "    # Create a DataFrame to store results of each model's performance\n",
        "    results_df = pd.DataFrame(columns=['Model'] + eval_metrics)\n",
        "\n",
        "    # Training every model and evaluating performance\n",
        "    for model_name, model in model_collection.items():\n",
        "        model.fit(X_train, y_train)  # Train the model on the training data\n",
        "\n",
        "        y_pred = model.predict(X_test)  # Make predictions on the test data\n",
        "\n",
        "        # Calculate performance statistics\n",
        "        acc = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
        "        prec = precision_score(y_test, y_pred, average='macro')  # Calculate precision\n",
        "        rec = recall_score(y_test, y_pred, average='macro')  # Calculate recall\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')  # Calculate F1 score\n",
        "\n",
        "        # Create a DataFrame for the current model's results\n",
        "        fresh_results = pd.DataFrame({'Model': [model_name],\n",
        "                                      'Accuracy': [acc],\n",
        "                                      'Precision': [prec],\n",
        "                                      'Recall': [rec],\n",
        "                                      'F1-score': [f1]})\n",
        "\n",
        "        # Append the current model's results to the results DataFrame\n",
        "        results_df = pd.concat([results_df, fresh_results], ignore_index=True)\n",
        "\n",
        "    return results_df  # Return the DataFrame containing all models' performance metrics"
      ],
      "metadata": {
        "id": "Mc7cK2dgP61m"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    best_params, score = perceptron_tuning()\n",
        "    print(\"Best Perceptron Hyperparameters:\", best_params)\n",
        "    print(\"Best Perceptron Accuracy:\", score)\n",
        "\n",
        "    best_params, score = mlp_tuning()\n",
        "    print(\"Best MLP Hyperparameters:\", best_params)\n",
        "    print(\"Best MLP Accuracy:\", score)\n",
        "    results = A3()\n",
        "    print(results)"
      ],
      "metadata": {
        "id": "iyFcE0aRQA0o"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmQUSq6DQCl1",
        "outputId": "5d6c138f-a8fc-447f-8701-586973b81db9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "Best Perceptron Hyperparameters: {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 100, 'alpha': 0.001}\n",
            "Best Perceptron Accuracy: 0.7318443682192346\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   5.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.6s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   0.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   4.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   3.8s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=  12.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   3.8s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   5.9s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   4.6s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   5.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=  10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.0s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   0.7s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   4.2s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.9s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.4s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "<ipython-input-60-890b9d525b40>:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, fresh_results], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best MLP Hyperparameters: {'tol': 1e-05, 'solver': 'lbfgs', 'max_iter': 1000, 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'alpha': 0.001, 'activation': 'logistic'}\n",
            "Best MLP Accuracy: 0.9680616370282952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Model  Accuracy  Precision    Recall  F1-score\n",
            "0     Perceptron  0.715962   0.808979  0.468420  0.485217\n",
            "1            MLP  0.946009   0.883765  0.935388  0.905400\n",
            "2            SVM  0.970266   0.972376  0.916647  0.941421\n",
            "3  Decision Tree  0.987480   0.984362  0.982701  0.983518\n",
            "4  Random Forest  0.992175   0.994932  0.979788  0.987137\n",
            "5       CatBoost  0.989045   0.980866  0.986077  0.983438\n",
            "6       AdaBoost  0.718310   0.862928  0.542068  0.583505\n",
            "7        XGBoost  0.982786   0.972937  0.965440  0.969112\n",
            "8    Naive Bayes  0.748044   0.720717  0.590909  0.628476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r5HH9iceQFWN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}